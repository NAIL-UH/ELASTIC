{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe53330a",
   "metadata": {},
   "source": [
    "# Tutorial for ELASTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov3.git\n",
    "!git clone https://github.com/mit-han-lab/once-for-all.git\n",
    "!git clone https://github.com/mit-han-lab/mcunet.git\n",
    "\n",
    "!pip install -r yolov3/requirements.txt\n",
    "!pip install -r once-for-all/requirements.txt\n",
    "!pip install -r mcunet/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('yolov3')\n",
    "sys.path.append('../mcunet')\n",
    "sys.path.append('../once-for-all')\n",
    "\n",
    "!pwd\n",
    "!ls\n",
    "print()\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3123bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17588c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, ast\n",
    "from torch import nn, optim\n",
    "\n",
    "from ofa.nas.accuracy_predictor.acc_predictor import AccuracyPredictor\n",
    "from search import IterativeEvolutionFinder\n",
    "from utils import MobileDetArchEncoder, SizePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25efae4",
   "metadata": {},
   "source": [
    "## Training Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc874763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train supernet\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task train --name supernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# progressive shrink depth only\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e6 --k 5 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e5 --k 5 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e4 --k 5 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e3 --k 5 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e2 --k 5 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk5e1 --k 5 --e 1\n",
    "\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e6 --k 3 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e5 --k 3 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e4 --k 3 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e3 --k 3 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e2 --k 3 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk3e1 --k 3 --e 1\n",
    "\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e6 --k 1 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e5 --k 1 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e4 --k 1 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e3 --k 1 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e2 --k 1 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 250 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task shrink --filename runs/train/supernet/weights/best.pt --name shrinkedk1e1 --k 1 --e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f47883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather data\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e6/weights/last.pt --name gatheredk5e6 --k 5 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e5/weights/last.pt --name gatheredk5e5 --k 5 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e4/weights/last.pt --name gatheredk5e4 --k 5 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e3/weights/last.pt --name gatheredk5e3 --k 5 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e2/weights/last.pt --name gatheredk5e2 --k 5 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk5e1/weights/last.pt --name gatheredk5e1 --k 5 --e 1\n",
    "\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e6/weights/last.pt --name gatheredk3e6 --k 3 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e5/weights/last.pt --name gatheredk3e5 --k 3 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e4/weights/last.pt --name gatheredk3e4 --k 3 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e3/weights/last.pt --name gatheredk3e3 --k 3 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e2/weights/last.pt --name gatheredk3e2 --k 3 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk3e1/weights/last.pt --name gatheredk3e1 --k 3 --e 1\n",
    "\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e6/weights/last.pt --name gatheredk1e6 --k 1 --e 6\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e5/weights/last.pt --name gatheredk1e5 --k 1 --e 5\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e4/weights/last.pt --name gatheredk1e4 --k 1 --e 4\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e3/weights/last.pt --name gatheredk1e3 --k 1 --e 3\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e2/weights/last.pt --name gatheredk1e2 --k 1 --e 2\n",
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --task gather --outpath data --filename runs/train/shrinkedk1e1/weights/last.pt --name gatheredk1e1 --k 1 --e 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edd460",
   "metadata": {},
   "source": [
    "## Train Accuracy Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "files = [f\"outputk5e{i}.xlsx\" for i in range(6, 0, -1)] + [f\"outputk3e{i}.xlsx\" for i in range(6, 0, -1)] + [f\"outputk1e{i}.xlsx\" for i in range(6, 0, -1)]\n",
    "\n",
    "x, y = [], []\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    subnet = df['subnet'].apply(ast.literal_eval).tolist()\n",
    "    acc = df['acc']\n",
    "    values = []\n",
    "    for s in acc:\n",
    "        t = eval(s, {\"np\": np})\n",
    "        values.append(float(t[2]))\n",
    "    x.extend(subnet)\n",
    "    y.extend(values)\n",
    "\n",
    "idx = torch.randperm(len(x))\n",
    "x = [x[i] for i in idx]\n",
    "y = np.array(y)[idx]\n",
    "\n",
    "encoder = MobileDetArchEncoder(\n",
    "    ks_list=[1, 3, 5],\n",
    "    expand_list=[1, 2, 3, 4, 5, 6],\n",
    "    depth_list=[1, 2, 3, 4, 5, 6],\n",
    "    n_stage=4\n",
    ")\n",
    "\n",
    "x = torch.stack([\n",
    "    torch.tensor(encoder.arch2feature({**arch, 'image_size': 224}), dtype=torch.float32)\n",
    "    for arch in x\n",
    "])\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "factor = 0.8\n",
    "x_train = x[:int(len(x)*factor)]\n",
    "y_train = y[:int(len(y)*factor)]\n",
    "x_test = x[int(len(x)*factor):]\n",
    "y_test = y[int(len(y)*factor):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b36964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy predictor\n",
    "predictor = AccuracyPredictor(\n",
    "    encoder,\n",
    "    checkpoint_path=None,\n",
    "    device='cpu'\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(predictor.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    predictor.train()\n",
    "    y_pred = predictor(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        predictor.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = predictor(x_test)\n",
    "            acc = criterion(y_pred, y_test)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "        print(f\"Test Loss: {acc.item():.4f}\")\n",
    "\n",
    "torch.save(predictor.state_dict(), 'predictor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056adbee",
   "metadata": {},
   "source": [
    "## Iterative Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct iterative search\n",
    "finder = IterativeEvolutionFinder(\n",
    "    efficiency_predictor=SizePredictor(\n",
    "        n_classes=20,\n",
    "        bn_param=(0.1, 1e-3),\n",
    "        width_mult_list=1.5,\n",
    "        ks_list=[1, 3, 5],\n",
    "        expand_ratio_list=[1, 2, 3, 4, 5, 6],\n",
    "        depth_list=[1, 2, 3, 4, 5],\n",
    "    ),\n",
    "    accuracy_predictor=AccuracyPredictor(\n",
    "        MobileDetArchEncoder(\n",
    "            ks_list=[1, 3, 5],\n",
    "            expand_list=[1, 2, 3, 4, 5, 6],\n",
    "            depth_list=[1, 2, 3, 4, 5],\n",
    "            n_stage=4\n",
    "        ),\n",
    "        checkpoint_path='predictor.pt',\n",
    "        device='cpu'\n",
    "    ),\n",
    "    arch_mutate_prob=0.1,\n",
    "    resolution_mutate_prob=0.5,\n",
    "    population_size=100,\n",
    "    max_time_budget=100 // 10,\n",
    "    parent_ratio=0.25,\n",
    "    mutation_ratio=0.5,\n",
    "    passthrough=0.5,\n",
    ")\n",
    "\n",
    "constraint = {\n",
    "    'minimum_weights': 1000000,\n",
    "    'maximum_weights': 1200000,\n",
    "}\n",
    "info = finder.run_evolution_search(constraint, 50, True)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0840df9",
   "metadata": {},
   "source": [
    "## Finetune Subnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python trainofa.py --img 224 --batch 64 --epochs 300 --data data/voc.yaml --cfg models/yolov3.yaml --weights '' --filename runs/train/supernet/weights/best.pt --task subnet --name subnet"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
